{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c7f018-a1bb-4a98-8ad2-367ab42a3afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 08:58:47.757476: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import os\n",
    "import sys\n",
    "matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from importlib import reload\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "import src.data_processing.data_augmentation as daug\n",
    "import src.models.CNN as CNN\n",
    "reload(CNN)\n",
    "from src.models.active_learning_kcluster import kCenterGreedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5830fd-6830-43ba-a0ad-880168cacba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in labelled data\n",
    "df = pd.read_csv(\"/Users/jameshill/PycharmProjects/bioacoustic-classifier/src/data/annotations/spectrogram_labels.csv\")\n",
    "df['filepath'] = \"/Users/jameshill/PycharmProjects/bioacoustic-classifier/data/processed/spectrogram_3s/\" + df['filename'] + \".png\"\n",
    "df['split_labels'] = df['label'].str.split('_and_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9213dd75-d159-4a9e-89ea-9c8c004a95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get arrays\n",
    "filepaths = df['filepath'].values\n",
    "# Initialise and fit multi-label encoder\n",
    "mle = MultiLabelBinarizer()\n",
    "multi_labels = mle.fit_transform(df['split_labels'])\n",
    "labels = multi_labels\n",
    "cnn = CNN.define_cnn(mle.classes_)\n",
    "assert cnn.output_shape[-1] == len(mle.classes_)\n",
    "label_msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1929)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "679467f8-1876-41ba-ae62-308510498713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['background_noise', 'blackcap', 'bluetit', 'carrion_crow',\n",
       "       'chiffchaff', 'common_whitethroat', 'dunnock', 'eurasian_skylark',\n",
       "       'pheasant', 'unknown_bird', 'unknown_bird_10', 'unknown_bird_11',\n",
       "       'unknown_bird_12', 'unknown_bird_13', 'unknown_bird_14',\n",
       "       'unknown_bird_15', 'unknown_bird_16', 'unknown_bird_17',\n",
       "       'unknown_bird_18', 'unknown_bird_2', 'unknown_bird_3',\n",
       "       'unknown_bird_4', 'unknown_bird_5', 'unknown_bird_9', 'woodpigeon',\n",
       "       'wren', 'yellowhammer'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mle.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330eec93-2ef3-4546-a927-43aa55a6fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for labelled data\n",
    "idx = np.arange(len(filepaths))\n",
    "rest_idx, test_idx = next(label_msss.split(idx, labels)) # test set will not be touched by anything until the very end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d27ea6-690d-41a9-8b01-e5814b0d9209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds_with_aug(filepaths, labels, indices, flags, batch_size=32, seed=1929):\n",
    "    idx = np.asarray(indices, dtype=int)\n",
    "    labs = np.asarray(labels)[idx].astype('float32')\n",
    "    paths = np.asarray(filepaths)[idx]\n",
    "    flgs = np.asarray(flags).astype('bool')\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labs, flgs))\n",
    "    ds = ds.shuffle(len(idx), seed=seed, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(daug.decode_image_with_aug, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def make_ds_no_aug(filepaths, labels, indices, batch_size):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((filepaths[indices],\n",
    "                                             labels[indices].astype('float32')))\n",
    "    ds = ds.map(daug.decode_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def unlabelled_decode(filename: tf.Tensor):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.resize(image, [64, 512])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "def make_unlabelled_ds(filepaths: np.ndarray, indices: np.ndarray, batch_size: int):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(filepaths[indices])\n",
    "    ds = ds.map(unlabelled_decode, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00b520c5-520b-4039-aed8-a4b8290144f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in unlabelled data\n",
    "# These will only be used for pretraining the autoencoder\n",
    "from pathlib import Path\n",
    "\n",
    "folder = Path(\"/Users/jameshill/PycharmProjects/bioacoustic-classifier/data/processed/spectrogram_3s/unlabelled\")\n",
    "files = np.array(sorted(str(p) for p in folder.glob(\"*.png\")), dtype=np.str_)\n",
    "\n",
    "# Split out some validation data for assessing the autoencoder\n",
    "ss = ShuffleSplit(n_splits=1, test_size=0.1, random_state=1929)\n",
    "unlabelled_train_idx, unlabelled_val_idx = next(ss.split(files))\n",
    "cae_train_ds = make_unlabelled_ds(files, unlabelled_train_idx, batch_size=64)\n",
    "cae_val_ds = make_unlabelled_ds(files, unlabelled_val_idx, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b6bcfd-0b76-4bd6-bd35-a250a3e8a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_encoder(input_shape=(64,512,1)):\n",
    "    inp = keras.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inp)\n",
    "    x = layers.MaxPooling2D(2)(x)             # 32x256\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(2)(x)             # 16x128\n",
    "    x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(2)(x)             # 8x64\n",
    "    x = layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\",\n",
    "                      kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n",
    "     #(8x64x256)\n",
    "    return keras.Model(inp, x, name=\"conv_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c5dd110-a219-4e4e-abd1-8d091a982b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cae(input_shape=(64,512,1)):\n",
    "    enc = conv_encoder(input_shape)\n",
    "    z   = enc.output                     # (8,64,256)\n",
    "\n",
    "    x = layers.UpSampling2D((2,2))(z)    # 16x128\n",
    "    x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.UpSampling2D((2,2))(x)    # 32x256\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.UpSampling2D((2,2))(x)    # 64x512\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    out = layers.Conv2D(1, 3, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "    cae = keras.Model(enc.input, out, name=\"cae\")\n",
    "    return cae, enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "050ef279-ee91-4aa5-a5b8-50824c4c2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cae_train_images = cae_train_ds.map(lambda x: (x,x))\n",
    "cae_val_images = cae_val_ds.map(lambda x: (x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf40ce-227f-4fe6-ae42-1b9ff961e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cae, enc = build_cae()\n",
    "cae.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\")\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='conv_ae.keras',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_loss')\n",
    "        ]\n",
    "# Include early stopping to protect against overfit. Patience is 10 - how many epochs before comparing loss.\n",
    "early_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                                         patience=10, restore_best_weights=True, verbose=1)\n",
    "# If loss starts to plateau, reduce the LR\n",
    "plateau_cb = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n",
    "                               patience=4, min_lr=1e-5, verbose=1)\n",
    "# Fit the model\n",
    "cae_history = cae.fit(cae_train_images, epochs=50, validation_data=cae_val_images, callbacks=[callbacks,early_cb,plateau_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc184a0f-bd1b-4067-8e97-a89cb1a45c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(None, 64, 512, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 512, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cae_train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef3f520-a3d5-4242-afb7-add54f46f9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: []\n"
     ]
    }
   ],
   "source": [
    "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa538308-3ed2-4204-b8e5-4e4b13cc764c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
