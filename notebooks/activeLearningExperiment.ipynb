{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1922d18b-2646-4e5f-b471-9dd24e36390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "02b138f7-a158-4e35-8e04-b0fed998bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in data ##\n",
    "df = pd.read_csv(\"/Users/jameshill/PycharmProjects/bioacoustic-classifier/src/data/annotations/spectrogram_labels.csv\")\n",
    "df['filepath'] = \"/Users/jameshill/PycharmProjects/bioacoustic-classifier/data/processed/spectrogram_3s/\" + df['filename'] + \".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9437e863-2ed5-4a33-8daa-d1e8f22fb1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up data for multi-label classification ##\n",
    "# Get all unique labels\n",
    "all_labels = set()\n",
    "for loc in df['label']:\n",
    "    species = loc.split('_and_')\n",
    "    all_labels.update(species)\n",
    "\n",
    "df['split_labels'] = df['label'].str.split('_and_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "efb2c9b2-821c-48ff-ba35-f54760b99534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 28)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get arrays\n",
    "filepaths = df['filepath'].values\n",
    "\n",
    "## Test/ train split ##\n",
    "# Extract indices of data, test/ train split on this\n",
    "# This is so images themselves do not need duplicating but instead augmentation will be applied when relevant index occurs\n",
    "idx = np.arange(len(filepaths))\n",
    "train_idx, test_val_idx = train_test_split(idx, test_size=0.3, random_state = 1929, shuffle=True)\n",
    "test_idx, val_idx = train_test_split(test_val_idx, test_size=0.8, random_state = 1929, shuffle=True)\n",
    "\n",
    "# Initialise and fit multi-label encoder\n",
    "mle = MultiLabelBinarizer() \n",
    "multi_labels = mle.fit_transform(df['split_labels'])\n",
    "\n",
    "labels = multi_labels\n",
    "np.shape(multi_labels)\n",
    "# Returns (1200, 28) - 1200 rows (samples) or 28 different categories (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4d170bb4-e8dd-40da-bc78-fb6265da6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_rare(train_labels, train_idx):\n",
    "    train_idx = np.asarray(train_idx, dtype=int)          \n",
    "\n",
    "    Yt = train_labels[train_idx]\n",
    "    class_freqs = Yt.sum(axis=0)\n",
    "    present = class_freqs > 0\n",
    "    most_freq = class_freqs[present].max() if present.any() else 1\n",
    "\n",
    "    upsample_factor = np.ones_like(class_freqs, dtype=float)\n",
    "    upsample_factor[present] = np.clip(np.ceil(most_freq / class_freqs[present]).astype(int),1,10)\n",
    "    upsample_factor = upsample_factor.astype(int)        \n",
    "\n",
    "    classes_upsampled = Yt * upsample_factor\n",
    "    label_upsample_factor = classes_upsampled.max(axis=1).astype(int)  \n",
    "    extra_counts = np.maximum(label_upsample_factor - 1, 0).astype(int)\n",
    "\n",
    "    base_idx = train_idx\n",
    "    dup_idx = np.repeat(train_idx, extra_counts)\n",
    "    all_idx = np.concatenate([base_idx, dup_idx])\n",
    "    all_flag = (np.concatenate([np.zeros(len(base_idx), bool),\n",
    "                                np.ones(len(dup_idx), bool)])\n",
    "                if dup_idx.size else np.zeros(len(base_idx), bool))\n",
    "\n",
    "    rng = np.random.default_rng(1929)\n",
    "    perm = rng.permutation(all_idx.shape[0])\n",
    "    all_idx  = all_idx[perm]\n",
    "    all_flag = all_flag[perm]\n",
    "    return all_idx, all_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "791c5be0-2726-4771-bf8c-e18a21650b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation functions\n",
    "def vertical_roll(image):\n",
    "    shift = tf.random.uniform(shape=[], minval=-5, maxval=6, dtype=tf.int32)\n",
    "    return tf.roll(image, shift=shift, axis=0)\n",
    "\n",
    "def horizontal_roll(image):\n",
    "    shift = tf.random.uniform(shape=[], minval=-50, maxval=51, dtype=tf.int32)\n",
    "    return tf.roll(image, shift=shift, axis=1)\n",
    "\n",
    "def warp(image):\n",
    "    angle = tf.random.uniform([], -0.05, 0.05)  # radians\n",
    "    rotated = tf.image.rotate(image, angles=angle, fill_mode=\"constant\")\n",
    "    return rotated\n",
    "\n",
    "def add_noise(image):\n",
    "    noise = tf.random.normal(tf.shape(image), mean=0.0, stddev=0.02)\n",
    "    noised = tf.clip_by_value(image + noise, 0.0, 1.0)\n",
    "    return noised\n",
    "\n",
    "# This is to augment the image by 3 of the 4 possible \n",
    "def augment_k_of_n(image, label, k=3):\n",
    "    ops = [vertical_roll, horizontal_roll, add_noise]\n",
    "    idx = tf.range(len(ops))\n",
    "    idx = tf.random.shuffle(idx)[:k]\n",
    "\n",
    "    def apply_op(im, op):\n",
    "        return tf.switch_case(op, branch_fns=[\n",
    "            lambda: vertical_roll(im),\n",
    "            lambda: horizontal_roll(im),\n",
    "            #lambda: warp(im),\n",
    "            lambda: add_noise(im)\n",
    "        ])\n",
    "\n",
    "    for op_idx in tf.unstack(idx):\n",
    "        image = apply_op(image, op_idx)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ca4b43fe-9dd1-4c02-8dbd-21a323bf0086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing function\n",
    "# Preprocessing needed as saving the images as PNGs and then reloading them with decode_png\n",
    "# This can result in unforeseen issues, so this function adjusts these as a failsafe\n",
    "def decode_image(filename, label):\n",
    "    # read in and process image\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.resize(image, [64, 512])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "def decode_image_with_aug(filename, label, do_aug):\n",
    "    # read in and process image\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.resize(image, [64, 512])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    # process if augment\n",
    "    def aug():\n",
    "        img, lbl = augment_k_of_n(image, label)\n",
    "        return img, lbl\n",
    "        \n",
    "    # process if no augment\n",
    "    def no_aug():\n",
    "        return image, label\n",
    "\n",
    "    # image and label are either aug output or no_aug output, depending on do_aug\n",
    "    image, label = tf.cond(do_aug, aug, no_aug)\n",
    "    return image, label\n",
    "\n",
    "def make_train_ds(filepaths, labels, indices, flags, batch_size = 32, seed = 1929):\n",
    "    \n",
    "    idx  = np.asarray(indices, dtype=int)\n",
    "    labs = np.asarray(labels)[idx].astype('float32')  \n",
    "    paths = np.asarray(filepaths)[idx]\n",
    "    flgs  = np.asarray(flags).astype('bool')\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labs, flgs))\n",
    "    ds = ds.shuffle(len(idx), seed=seed, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(decode_image_with_aug, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def make_eval_ds(filepaths, labels, indices, batch_size):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((filepaths[indices],\n",
    "                                             labels[indices].astype('float32')))\n",
    "    ds = ds.map(decode_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "48fb7c72-5640-4bc4-8348-741487441e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample first epoch #\n",
    "epoch_idx, epoch_flag = upsample_rare(train_labels = labels, train_idx = train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "207f5ce1-dd23-4c4d-8126-2938b42fd3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function on all data and labels but using indices and flags produced by upsampled training data\n",
    "train_ds = make_train_ds(filepaths, labels, epoch_idx, epoch_flag, batch_size=32)\n",
    "val_ds = make_eval_ds(filepaths, labels, val_idx, batch_size=32)\n",
    "test_ds = make_eval_ds(filepaths, labels, test_idx, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01526dc4-2747-4a43-a98a-c1b7b671abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Take one batch from the dataset\n",
    "for images, labels in train_ds.take(10):\n",
    "    img = images[0].numpy().squeeze(-1)  # (64, 512)\n",
    "    plt.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c866081-adc6-4709-89c5-8cd3766737ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model architecture\n",
    "x = keras.Input(shape=(64, 512, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(len(mle.classes_), activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=x, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7872ad46-c617-499b-93f0-0e25e820eb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for i in range(1,epochs+1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fec01c0-4f1e-487d-9d2c-9035a24e2276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
