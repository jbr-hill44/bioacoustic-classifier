{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1922d18b-2646-4e5f-b471-9dd24e36390c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 11:26:05.200801: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b138f7-a158-4e35-8e04-b0fed998bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in data ##\n",
    "df = pd.read_csv(\"/Users/jameshill/PycharmProjects/bioacoustic-classifier/src/data/annotations/spectrogram_labels.csv\")\n",
    "df['filepath'] = \"/Users/jameshill/PycharmProjects/bioacoustic-classifier/data/processed/spectrogram_3s/\" + df['filename'] + \".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9437e863-2ed5-4a33-8daa-d1e8f22fb1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up data for multi-label classification ##\n",
    "# Get all unique labels\n",
    "all_labels = set()\n",
    "for loc in df['label']:\n",
    "    species = loc.split('_and_')\n",
    "    all_labels.update(species)\n",
    "\n",
    "df['split_labels'] = df['label'].str.split('_and_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efb2c9b2-821c-48ff-ba35-f54760b99534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define preprocessing function\n",
    "# Preprocessing needed as saving the images as PNGs and then reloading them with decode_png\n",
    "# This can result in unforeseen issues, so this function adjusts these as a failsafe\n",
    "def decode_image(filename, label):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, [64, 512])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "# Initialise and fit multi-label encoder\n",
    "mle = MultiLabelBinarizer() \n",
    "multi_labels = mle.fit_transform(df['split_labels'])\n",
    "\n",
    "# Get arrays\n",
    "filepaths = df['filepath'].values\n",
    "labels = multi_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6aab9a4e-b3ab-406b-af29-df9606f77707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 28)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(multi_labels)\n",
    "# Returns (1200, 28) - 1200 rows (samples) or 28 different categories (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a57e39-f2ca-4206-9b49-ac2e479159bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test/ train split ##\n",
    "# Extract indices of data, test/ train split on this\n",
    "# This is so images themselves do not need duplicating but instead augmentation will be applied when relevant index occurs\n",
    "idx = np.arange(len(filepaths))\n",
    "train_idx, test_val_idx = train_test_split(idx, test_size=0.3, random_state = 1929, shuffle=True)\n",
    "test_idx, val_idx = train_test_split(test_val_idx, test_size=0.8, random_state = 1929, shuffle=True)\n",
    "\n",
    "train_labels = labels[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ffc6e0b2-17a2-47a8-879b-f30ba101314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 28)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ab3df-b45f-437c-8358-01fd0e3628f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "938f7e1c-65b9-42f8-9799-88055dadf160",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85122587-74bc-4ccc-97ed-af98086df35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([287,  26,   0,   7, 425,   1,  10,  23,   9,   6,   1,   2,   4,\n",
       "         1,   6,   1,   4,   1,   7,   0,   1,   2,   3,   1,  16,   6,\n",
       "       106, 143])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_freqs = train_labels.sum(axis=0)\n",
    "class_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53cb519b-c99b-411c-bf6e-9f22d16f224a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.00e+00, 1.70e+01, 4.25e+08, 6.10e+01, 1.00e+00, 4.25e+02,\n",
       "       4.30e+01, 1.90e+01, 4.80e+01, 7.10e+01, 4.25e+02, 2.13e+02,\n",
       "       1.07e+02, 4.25e+02, 7.10e+01, 4.25e+02, 1.07e+02, 4.25e+02,\n",
       "       6.10e+01, 4.25e+08, 4.25e+02, 2.13e+02, 1.42e+02, 4.25e+02,\n",
       "       2.70e+01, 7.10e+01, 5.00e+00, 3.00e+00])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq = class_freqs.max()\n",
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba0924-e0af-4d92-8b07-841117f9d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_i = np.ones(len(train_idx), dtype=int)\n",
    "repeat_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe20a95f-2d41-4f4a-a27b-d3c46d899e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d170bb4-e8dd-40da-bc78-fb6265da6159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upsample_rare(labels, index):\n",
    "    class_freqs = train_labels.sum(axis=0)\n",
    "    most_freq = class_freqs.max()\n",
    "    upsample_factor = np.clip(np.floor((most_freq - class_freqs) / (class_freqs + eps)), 1, 10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791c5be0-2726-4771-bf8c-e18a21650b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation functions\n",
    "def vertical_roll(image):\n",
    "    shift = tf.random.uniform(shape=[], minval=-5, maxval=6, dtype=tf.int32)\n",
    "    return tf.roll(image, shift=shift, axis=0)\n",
    "\n",
    "def horizontal_roll(image):\n",
    "    shift = tf.random.uniform(shape=[], minval=-50, maxval=51, dtype=tf.int32)\n",
    "    return tf.roll(image, shift=shift, axis=1)\n",
    "\n",
    "def warp(image):\n",
    "    angle = tf.random.uniform([], -0.05, 0.05)  \n",
    "    warped = tfa.image.rotate(image, angles=angle, fill_mode=\"constant\", fill_value=0.0)\n",
    "    return warped\n",
    "\n",
    "def add_noise(image):\n",
    "    noise = tf.random.normal(tf.shape(image), mean=0.0, stddev=0.02)\n",
    "    noised = tf.clip_by_value(image + noise, 0.0, 0.1)\n",
    "    return noised\n",
    "\n",
    "# This is to augment the image by 3 of the 4 possible \n",
    "def augment_k_of_n(image, label, k=3):\n",
    "    ops = [vertical_roll, horizontal_roll, warp, add_noise]\n",
    "    idx = tf.range(len(ops))\n",
    "    idx = tf.random.shuffle(idx)[:k]\n",
    "\n",
    "    def apply_op(im, op):\n",
    "        return tf.switch_case(op, branch_fns=[\n",
    "            lambda: vertical_roll(im),\n",
    "            lambda: horizontal_roll(im),\n",
    "            lambda: warp(im),\n",
    "            lambda: add_noise(im)\n",
    "        ])\n",
    "\n",
    "    for op_idx in tf.unstack(idx):\n",
    "        image = apply_op(image, op_idx)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48fb7c72-5640-4bc4-8348-741487441e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 0, 1], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4b43fe-9dd1-4c02-8dbd-21a323bf0086",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactive_learning_kcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m kCenterGreedy\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.models.active_learning_kcluster import kCenterGreedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f5ce1-dd23-4c4d-8126-2938b42fd3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
